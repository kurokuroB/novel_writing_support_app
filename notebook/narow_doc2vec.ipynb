{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import requests\n",
    "import pandas as pd\n",
    "from janome.tokenizer import Tokenizer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データ取得\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# なろうapiのエンドポイント\n",
    "URL = \"https://api.syosetu.com/novelapi/api/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "st: 1\n",
      "lim 499\n",
      "done\n",
      "\n",
      "st: 500\n",
      "lim 500\n",
      "done\n",
      "\n",
      "st: 1000\n",
      "lim 500\n",
      "done\n",
      "\n",
      "st: 1500\n",
      "lim 500\n",
      "done\n",
      "\n",
      "st: 2000\n",
      "lim 500\n",
      "done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# データ取得\n",
    "\n",
    "all_data = []\n",
    "loop_cnt = 0\n",
    "\n",
    "st_lim_pair = [(1, 499), (500, 500), (1000, 500), (1500, 500), (2000, 500)]\n",
    "for st, lim in st_lim_pair:\n",
    "    print(\"st:\", st)  # st：表示開始位置。max2000\n",
    "    print(\"lim\", lim)  # lim:最大出力数。max500\n",
    "\n",
    "    params = {\n",
    "        \"of\": \"s\",\n",
    "        \"order\": \"hyoka\",\n",
    "        \"type\": \"er\",  # 完結済み連載小説に絞る\n",
    "        \"out\": \"json\",\n",
    "        \"lim\": lim,\n",
    "        \"st\": st,\n",
    "    }  # nコードとあらすじをjsonで出力\n",
    "\n",
    "    res = requests.get(URL, params=params)\n",
    "    res = res.json()\n",
    "    new_data = res[1:]\n",
    "    all_data.extend(new_data)\n",
    "    print(\"done\")\n",
    "    print()\n",
    "df = pd.DataFrame(all_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# doc2vec 用学習データ作成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2499/2499 [00:27<00:00, 89.42it/s] \n"
     ]
    }
   ],
   "source": [
    "all_story = df.story.to_list()\n",
    "all_wakati_story = []\n",
    "for story in tqdm(all_story):\n",
    "    wakati_story = list(tokenizer.tokenize(story, wakati=True))\n",
    "    all_wakati_story.append(wakati_story)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# doc2vec 学習・保存\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(all_wakati_story)]\n",
    "model = Doc2Vec(documents, vector_size=100, window=5, min_count=1, workers=4, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../model/doc2vec\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "app-utU9GFLq-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
